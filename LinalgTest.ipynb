{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on instructions from https://changhsinlee.com/install-pyspark-windows-jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.context.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.mllib.linalg\n",
    "import pyspark.mllib.linalg.distributed\n",
    "import scipy.io\n",
    "import scipy.sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = np.array([0, 2, 2, 0, 1, 2])\n",
    "col = np.array([0, 0, 1, 2, 2, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6]) \n",
    "mat = scipy.sparse.coo_matrix((data, (row, col)), shape=(3, 3))\n",
    "(rows, cols) = mat.shape\n",
    "data_rows = []\n",
    "for row in range(rows):\n",
    "    data_row = mat.getrow(row)\n",
    "    data_rows = data_rows + [pyspark.mllib.linalg.Vectors.sparse(cols, zip(data_row.indices, data_row.data))]\n",
    "rdd_rows = sc.parallelize(data_rows)\n",
    "rowmatrix = pyspark.mllib.linalg.distributed.RowMatrix(rdd_rows)\n",
    "print(rowmatrix.rows.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.mmread('rw136.mtx')\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rows, cols) = mat.shape\n",
    "data_rows = []\n",
    "for row in range(rows):\n",
    "    data_row = mat.getrow(row)\n",
    "    data_rows = data_rows + [pyspark.mllib.linalg.Vectors.sparse(cols, zip(data_row.indices, data_row.data))]\n",
    "rdd_rows = sc.parallelize(data_rows)\n",
    "rowmatrix = pyspark.mllib.linalg.distributed.RowMatrix(rdd_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowmatrix.computePrincipalComponents(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
